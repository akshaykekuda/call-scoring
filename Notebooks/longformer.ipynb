{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import LongformerTokenizer, LongformerForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import unidecode\n",
    "import contractions\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PrepareDf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pt = '/mnt/transcriber/Call_Scoring/transcriptions/csr_ch/train/'\n",
    "test_pt = '/mnt/transcriber/Call_Scoring/transcriptions/csr_ch/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_handscored_p ='../ScoringDetail_viw_all_subscore.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_score_categories = ['Cross Selling', 'Creates Incentive', 'Education', 'Processes', 'Product Knowledge', 'Greeting', 'Professionalism', 'Confidence',  'Retention',\n",
    "                        'Documentation']\n",
    "scoring_criteria = sub_score_categories[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe creation done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12684/12684 [00:31<00:00, 400.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Calls = 12497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2407/2407 [00:06<00:00, 373.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Calls = 2404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score_df, q_text = prepare_score_df(\n",
    "    path_to_handscored_p, workgroup='all')\n",
    "train_df = prepare_trancript_score_df(score_df, q_text, train_pt, None)\n",
    "test_df = prepare_trancript_score_df(score_df, q_text, test_pt, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(arr):\n",
    "    arr = [txt.capitalize() for txt in arr]\n",
    "    return '. '.join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.text = train_df.text.apply(lambda x: post_process(x))\n",
    "test_df.text = test_df.text.apply(lambda x: post_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# checkpoint='allenai/longformer-base-4096'\n",
    "# checkpoint = 'distilbert-base-uncased'\n",
    "from transformers import BigBirdTokenizer, BigBirdForSequenceClassification\n",
    "checkpoint = 'google/bigbird-roberta-base'\n",
    "tokenizer = BigBirdTokenizer.from_pretrained(checkpoint)\n",
    "model = BigBirdForSequenceClassification.from_pretrained(checkpoint, num_labels=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    new_dict = tokenizer(example[\"text\"], truncation=True)\n",
    "    new_dict['labels'] = [example[criteria] for criteria in scoring_criteria]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c501f4702f4b3fa53b39badf18915e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12497 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26545fcde4f34fa68811ee3ab9cd40c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2404 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = train_ds.column_names\n",
    "tokenized_ds_train = train_ds.map(preprocess_function, remove_columns=cols)\n",
    "tokenized_ds_test = test_ds.map(preprocess_function, remove_columns=cols)\n",
    "tokenized_ds_train.set_format('torch')\n",
    "tokenized_ds_test.set_format('torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        for i in range(self.model.config.num_labels//2):\n",
    "            loss = loss_fn(outputs[0][:, 2*i:2*(i+1)], labels[:, i])\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    pos_proba = logits[:, [i for i in range(1, logits.shape[1], 2)]]\n",
    "    auc_scores = roc_auc_score(labels, pos_proba, average=None)\n",
    "    result = {}\n",
    "    for i in range(len(auc_scores)):\n",
    "        result[scoring_criteria[i]] = auc_scores[i]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../logs/bigbird\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    report_to='wandb',\n",
    "    eval_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    run_name='bigbird'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MultilabelTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds_train,\n",
    "    eval_dataset=tokenized_ds_test,\n",
    "    data_collator = data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kekuak/miniconda3/envs/call_scoring/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 12497\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4689\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkekuda95\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/transcriber/Call_Scoring/Notebooks/wandb/run-20220923_083623-2m71uoal</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kekuda95/huggingface/runs/2m71uoal\" target=\"_blank\">bigbird</a></strong> to <a href=\"https://wandb.ai/kekuda95/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 2090 to 2112 to be a multiple of `config.block_size`: 64\n",
      "/home/kekuak/miniconda3/envs/call_scoring/lib/python3.7/site-packages/transformers/models/big_bird/modeling_big_bird.py:978: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  * num_indices_to_pick_from\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Native Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_CLF_HEAD(nn.Module):\n",
    "    def __init__(self, dim_size, num_classes, dropout=0.2):\n",
    "        super(BERT_CLF_HEAD, self).__init__()\n",
    "        self.pre_classifier = nn.Linear(dim_size, dim_size)\n",
    "        self.classifier = nn.Linear(dim_size, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.pre_classifier(x)\n",
    "        logits = self.dropout(self.classifier(out))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "num_labels = 8\n",
    "bert_head = BERT_CLF_HEAD(dim_size=768, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_CLF_HEAD(\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "bert_head.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    " \n",
    "  def __init__(self,df):\n",
    "        self.df = df\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, tokenizer, window_size, stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "    def collate_fn(self, batch):\n",
    "        tokenized_texts = []\n",
    "        labels = []\n",
    "        call_ids = []\n",
    "        for sample in batch:\n",
    "            text_arr = sample.text\n",
    "            text_len = len(text_arr)\n",
    "            start = 0\n",
    "            slice_list =[]\n",
    "            while(start<text_len):\n",
    "                end = min(text_len, start+self.window_size)\n",
    "                text_slice = text_arr[start:end]\n",
    "                start+=self.stride\n",
    "                processed_text = '. '.join(text_slice)\n",
    "                slice_list.append(processed_text)\n",
    "                lens.append()\n",
    "            \n",
    "            tokenized_slices = self.tokenizer(slice_list, truncation=True, padding=True, return_tensors='pt')\n",
    "            tokenized_texts.append(tokenized_slices)\n",
    "            \n",
    "            labels.append(([sample[criteria] for criteria in scoring_criteria]))\n",
    "            call_ids.append(sample['InteractionIdKey'])\n",
    "        labels = torch.tensor(labels)\n",
    "        return {\"tokenized_text\": tokenized_texts, 'labels': labels, \"call_id\": call_ids} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collate1:\n",
    "    def __init__(self, tokenizer, window_size, stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "    def collate_fn(self, batch):\n",
    "        tokenized_texts = []\n",
    "        labels = []\n",
    "        call_ids = []\n",
    "        lens = []\n",
    "        slice_list =[]\n",
    "        for sample in batch:\n",
    "            text_arr = sample.text\n",
    "            text_len = len(text_arr)\n",
    "            start = 0\n",
    "            num_slices = 0\n",
    "            while(start<text_len):\n",
    "                end = min(text_len, start+self.window_size)\n",
    "                text_slice = text_arr[start:end]\n",
    "                start+=self.stride\n",
    "                processed_text = '. '.join(text_slice)\n",
    "                slice_list.append(processed_text)\n",
    "                num_slices+=1\n",
    "            lens.append(num_slices)\n",
    "            \n",
    "            labels.append(([sample[criteria] for criteria in scoring_criteria]))\n",
    "            call_ids.append(sample['InteractionIdKey'])\n",
    "        tokenized_slices = self.tokenizer(slice_list, truncation=True, padding=True, return_tensors='pt')\n",
    "        labels = torch.tensor(labels)\n",
    "        return {\"tokenized_text\": tokenized_slices, 'labels': labels, \"call_id\": call_ids, \"lens\":lens} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, train_ds, test_ds, epochs=3, lr=5e-5, bs=8, embed_size=768):\n",
    "        self.train_dataloader = DataLoader(train_ds, batch_size=bs, collate_fn=data_collator)\n",
    "        self.test_dataloader = DataLoader(test_ds, batch_size=bs, collate_fn=data_collator)\n",
    "        self.num_epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.bs = bs\n",
    "        self.embed_size = embed_size\n",
    "        \n",
    "    def compute_loss(self, logits, labels):\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        for i in range(num_labels//2):\n",
    "            loss = loss_fn(logits[:, 2*i:2*(i+1)], labels[:, i])\n",
    "        return loss\n",
    "    \n",
    "    def compute_metrics(self, eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        pos_proba = logits[:, [i for i in range(1, logits.shape[1], 2)]]\n",
    "        auc_scores = roc_auc_score(labels, pos_proba, average=None)\n",
    "        result = {}\n",
    "        for i in range(len(auc_scores)):\n",
    "            result[scoring_criteria[i]] = auc_scores[i]\n",
    "        return result\n",
    "    \n",
    "    def compute_logits(self, batch):\n",
    "        input_id_chunks = torch.split(batch['input_ids'], 512, -1)\n",
    "        attention_mask_chunks = torch.split(batch['attention_mask'], 512, -1)\n",
    "        cls_arr = []\n",
    "        for input_ids, attention_mask in zip(input_id_chunks, attention_mask_chunks):\n",
    "            chunk_batch = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "            outputs = model(**chunk_batch, output_hidden_states=True)\n",
    "            last_hidden_states = outputs.hidden_states[-1]\n",
    "            cls_token_embed = last_hidden_states[:,0,:]\n",
    "            cls_arr.append(cls_token_embed)        \n",
    "        cls_embed_mean = torch.mean(torch.stack(cls_arr), dim=0)\n",
    "        logits = bert_head(cls_embed_mean)\n",
    "        return logits\n",
    "\n",
    "    def compute_sliding_logits(self, batch):\n",
    "        cls_embeds = torch.empty((self.bs, self.embed_size), device=device)\n",
    "        for idx , sample in enumerate(batch['tokenized_text']):            \n",
    "            chunk_batch = {'input_ids': sample['input_ids'].to(device), 'attention_mask': sample['attention_mask'].to(device)}\n",
    "            outputs = model(**chunk_batch, output_hidden_states=True)\n",
    "            last_hidden_states = outputs.hidden_states[-1]\n",
    "            cls_token_embed = last_hidden_states[:,0,:]\n",
    "            # print(\"cls_token_embed\", cls_token_embed.shape)\n",
    "            cls_embed_mean = torch.mean(cls_token_embed, dim=0)\n",
    "            # print(\"cls_embed_mean\", cls_embed_mean.shape)\n",
    "            # print(\"cls_embeds\", cls_embeds)\n",
    "            cls_embeds[idx, :] = cls_embed_mean\n",
    "        logits = bert_head(cls_embeds)\n",
    "        return logits\n",
    "\n",
    "    def compute_all_logits(self, batch):\n",
    "        chunk_batch = {'input_ids': batch['tokenized_text']['input_ids'].to(device), 'attention_mask': batch['tokenized_text']['attention_mask'].to(device)}\n",
    "        outputs = model(**chunk_batch, output_hidden_states=True)\n",
    "        last_hidden_states = outputs.hidden_states[-1]\n",
    "        cls_token_embed = last_hidden_states[:,0,:]        \n",
    "        output = torch.stack([torch.mean(chunk, dim=0) for chunk in torch.split(cls_token_embed, batch['lens'])])\n",
    "        logits = bert_head(output)\n",
    "        return logits\n",
    "    \n",
    "    def get_optimizer(self):\n",
    "        return AdamW(model.parameters(), self.lr)\n",
    "    \n",
    "    def get_scheduler(self):\n",
    "        self.num_training_steps = self.num_epochs * len(self.train_dataloader)\n",
    "        lr_scheduler = get_scheduler(\n",
    "            name=\"linear\", optimizer=self.optimizer, num_warmup_steps=0, num_training_steps=self.num_training_steps\n",
    "        )\n",
    "        return lr_scheduler\n",
    "        \n",
    "    def train(self):\n",
    "        self.optimizer = self.get_optimizer()\n",
    "        self.lr_scheduler  = self.get_scheduler()\n",
    "        model.train()\n",
    "        bert_head.train()\n",
    "        progress_bar = tqdm(range(self.num_training_steps))\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for batch in self.train_dataloader:\n",
    "                logits = self.compute_all_logits(batch)\n",
    "                labels = batch['labels'].to(device)\n",
    "                loss = self.compute_loss(logits, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.lr_scheduler.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                progress_bar.update(1)\n",
    "            self.evaluate()\n",
    "            \n",
    "    def evaluate(self):\n",
    "        print(\"Running Eval\")\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        val_loss = 0\n",
    "        for batch in self.test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                logits = self.compute_sliding_logits(batch)\n",
    "                all_logits.append(logits.numpy())\n",
    "            labels = batch['labels'].to(device)\n",
    "            val_loss += self.compute_loss(logits, labels).item()\n",
    "            all_labels.append(labels.numpy())\n",
    "        all_logits = np.vstack(all_logits)\n",
    "        all_labels = np.vstack(all_labels)\n",
    "        eval_pred = (all_logits, all_labels)\n",
    "            \n",
    "        metrics = self.compute_metrics(eval_pred)\n",
    "        metrics[\"val_loss\"] = val_loss/len(self.test_dataloader)\n",
    "        print(metrics)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(lr = 2e-5, bs=8, train_ds=tokenized_ds_train, test_ds=tokenized_ds_test, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54b25d064154250b2c4bd0d28d1f7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Eval\n",
      "{'Cross Selling': 0.4735731094309147, 'Creates Incentive': 0.46843593793421245, 'Education': 0.537360536806054, 'Processes': 0.5867165075103398}\n",
      "Running Eval\n",
      "{'Cross Selling': 0.44059693387359544, 'Creates Incentive': 0.45295607484196865, 'Education': 0.533454142952336, 'Processes': 0.633187638925238}\n",
      "Running Eval\n",
      "{'Cross Selling': 0.4636144645418216, 'Creates Incentive': 0.43130762384840243, 'Education': 0.5574542846998184, 'Processes': 0.6299546621387591}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = Collate(tokenizer, window_size=5, stride=3)\n",
    "data_collator = collator.collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MyDataset(train_df.reset_index())\n",
    "test_ds = MyDataset(test_df.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(train_ds=train_ds, test_ds=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate slices across batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = Collate1(tokenizer, window_size=5, stride=3)\n",
    "data_collator = collator.collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MyDataset(train_df.reset_index())\n",
    "test_ds = MyDataset(test_df.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(train_ds=train_ds, test_ds=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mac_torch",
   "language": "python",
   "name": "mac_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "daf82e5e90d16040059b2304462642dc0e7c83f222921802b45599b0c2d201a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
