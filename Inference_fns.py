# -*- coding: utf-8 -*-
"""Inference_fns

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gtEyI0DrfZVDxgsIGqETSfGBeIPuvqU4
"""

from tqdm import tqdm
import torch
from Preprocessing import preprocess_transcript
from torchtext.data.utils import get_tokenizer
from DataLoader_fns import get_indices
from sklearn.metrics import classification_report, f1_score

def get_metrics(dataloader, encoder):
  classification_arr = []
  target_arr =[]
  encoder.eval()
  total_correct = 0
  batch_size = dataloader.batch_size
  for batch in tqdm(dataloader):
    output, scores = encoder(batch['indices'])
    for i in range(output.shape[0]):
      classification = torch.argmax(output[i]).item()
      target = batch['category'][i]
      classification_arr.append(classification)
      target_arr.append(target)
      if target == classification:
        total_correct+=1
  encoder.train()
  acc = total_correct/(len(dataloader) * batch_size)
  f1 = f1_score(target_arr, classification_arr)
  clr = classification_report(target_arr, classification_arr)
  print("Accuracy: {} F1: {}".format(acc, f1))
  metrics = {'accuracy':acc, 'f1':f1, 'clr':clr}
  return metrics

def predict(transcript, encoder, classifier, vocab):
  
  word_tokenizer = get_tokenizer('basic_english')
  sents = preprocess_transcript(transcript)
  max_len = 0
  for sent in sents:
    tokens = word_tokenizer(sent)
    if len(tokens) > max_len:
      max_len = len(tokens)

  indices = []
  for sent in sents:
    indices.append(get_indices(sent, max_len, vocab))
  indices = torch.tensor(indices)

  indices = indices.unsqueeze_(0)

  output, hidden = encoder(indices)
  output = output[:,-1,:]

  output = classifier(output)
  classification = torch.argmax(output).item()

  return classification
